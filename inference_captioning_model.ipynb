{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yJvEkKev3kjo"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/transformers.git accelerate\n",
        "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFfW5KsRUiJe"
      },
      "source": [
        "#Login huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sUNu69m7ClA"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Replace 'your_hugging_face_token' with your actual Hugging Face token\n",
        "login(token=\"<Your TOKEN>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuiYH30vUM3D"
      },
      "source": [
        "#Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M8oSaAm_r70"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
        "\n",
        "\n",
        "\n",
        "loaded_model = PaliGemmaForConditionalGeneration.from_pretrained(\"Ohmmy3847/paligemma_vqav4\")\n",
        "loaded_processor = AutoProcessor.from_pretrained(\"google/paligemma-3b-pt-224\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c4rGWHWUIt0"
      },
      "source": [
        "# inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILYRZi2493BG"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "# raw_image = Image.open(\"/content/image_006.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVKiDeQ6PLAj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = \"cuda\"\n",
        "loaded_model = loaded_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p56PnsWm7gSM",
        "outputId": "31f33214-dc81-4ab7-c172-3f326c3741b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "คนนอนอยู่บนเตียงข้างโต๊ะทำงานที่ตั้งอยู่บนเตียง\n",
            "CPU times: user 1.64 s, sys: 160 ms, total: 1.8 s\n",
            "Wall time: 1.75 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "raw_image = Image.open(\"/content/IMG_1935.jpeg\")\n",
        "prompt = \"อธิบายภาพนี้เป็นภาษาไทยให้ละเอียดที่สุดเท่าที่เป็นไปได้\"\n",
        "inputs = loaded_processor(prompt, raw_image.convert(\"RGB\"), return_tensors=\"pt\").to(device)\n",
        "output = loaded_model.generate(**inputs, max_new_tokens=256)\n",
        "caption = loaded_processor.decode(output[0], skip_special_tokens=True)[len(prompt):]\n",
        "display(raw_image)\n",
        "print(caption)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}